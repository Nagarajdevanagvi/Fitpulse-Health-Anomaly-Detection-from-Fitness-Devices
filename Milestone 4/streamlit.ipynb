{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NkRCNaCprRDk"
      },
      "outputs": [],
      "source": [
        "!pip install fastapi uvicorn streamlit pyngrok pandas requests prophet tsfresh scikit-learn matplotlib    --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DEBfbjXrrYMY"
      },
      "outputs": [],
      "source": [
        "from pyngrok import ngrok\n",
        "\n",
        "# Please replace 'YOUR_NGROK_AUTHTOKEN' with your actual ngrok authentication token\n",
        "ngrok.set_auth_token('38D0P5dopGSihiwuvxUSqExgpzY_53JxC4N2ab8HiPSsbwHUh')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "11McWElyrZAs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b085fd9-1695-4a91-cdb6-ecf0036362de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting backend.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile backend.py\n",
        "\n",
        "from fastapi import FastAPI, UploadFile, File\n",
        "from fastapi.responses import JSONResponse\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import traceback\n",
        "\n",
        "from prophet import Prophet\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.cluster import DBSCAN\n",
        "\n",
        "app = FastAPI(title=\"FitPulse â€“ Health Anomaly Backend\")\n",
        "\n",
        "# ---------------- GLOBAL STATE ----------------\n",
        "CLEAN_DF = None\n",
        "FEATURE_DF = None\n",
        "ALERTS_DF = None\n",
        "\n",
        "# ---------------- ERROR HANDLER ----------------\n",
        "@app.exception_handler(Exception)\n",
        "async def global_exception_handler(request, exc):\n",
        "    trace = traceback.format_exc()\n",
        "    print(trace)\n",
        "    return JSONResponse(\n",
        "        status_code=500,\n",
        "        content={\"error\": \"Backend crashed\", \"trace\": trace}\n",
        "    )\n",
        "\n",
        "# ==================================================\n",
        "# MODULE 1 â€“ PREPROCESSING\n",
        "# ==================================================\n",
        "@app.post(\"/preprocess\")\n",
        "def preprocess(file: UploadFile = File(...)):\n",
        "    global CLEAN_DF\n",
        "\n",
        "    df = pd.read_csv(file.file)\n",
        "\n",
        "    REQUIRED = [\"Id\", \"date\", \"avg_heart_rate\", \"daily_steps\", \"hours_sleep\"]\n",
        "    missing = [c for c in REQUIRED if c not in df.columns]\n",
        "    if missing:\n",
        "        return JSONResponse(status_code=400, content={\"error\": f\"Missing {missing}\"})\n",
        "\n",
        "    df = df.rename(columns={\n",
        "        \"Id\": \"user_id\",\n",
        "        \"avg_heart_rate\": \"heart_rate\",\n",
        "        \"daily_steps\": \"steps\",\n",
        "        \"hours_sleep\": \"sleep\"\n",
        "    })\n",
        "\n",
        "    df[\"date\"] = pd.to_datetime(df[\"date\"], errors=\"coerce\")\n",
        "    df = df.dropna(subset=[\"date\"])\n",
        "\n",
        "    for col in [\"heart_rate\", \"steps\", \"sleep\"]:\n",
        "        df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
        "\n",
        "    df[\"heart_rate\"].fillna(df[\"heart_rate\"].median(), inplace=True)\n",
        "    df[\"steps\"].fillna(0, inplace=True)\n",
        "    df[\"sleep\"].fillna(df[\"sleep\"].median(), inplace=True)\n",
        "\n",
        "    df = (\n",
        "        df.set_index(\"date\")\n",
        "        .groupby(\"user_id\")[[\"heart_rate\", \"steps\", \"sleep\"]]\n",
        "        .resample(\"D\")\n",
        "        .mean()\n",
        "        .reset_index()\n",
        "    )\n",
        "\n",
        "    CLEAN_DF = df\n",
        "    df.to_csv(\"clean_data.csv\", index=False)\n",
        "\n",
        "    return {\"status\": \"success\", \"rows\": len(df)}\n",
        "\n",
        "# ==================================================\n",
        "# MODULE 2 â€“ FEATURE EXTRACTION + MODELING\n",
        "# ==================================================\n",
        "@app.post(\"/module2\")\n",
        "def module2():\n",
        "    global CLEAN_DF, FEATURE_DF\n",
        "\n",
        "    if CLEAN_DF is None:\n",
        "        return JSONResponse(status_code=400, content={\"error\": \"Run Module 1 first\"})\n",
        "\n",
        "    df = CLEAN_DF.sort_values([\"user_id\", \"date\"])\n",
        "\n",
        "    # ---------- Feature Extraction ----------\n",
        "    df[\"hr_7d_mean\"] = df.groupby(\"user_id\")[\"heart_rate\"].transform(\n",
        "        lambda x: x.rolling(7, min_periods=1).mean()\n",
        "    )\n",
        "    df[\"hr_7d_std\"] = df.groupby(\"user_id\")[\"heart_rate\"].transform(\n",
        "        lambda x: x.rolling(7, min_periods=1).std().fillna(0)\n",
        "    )\n",
        "    df[\"steps_7d_mean\"] = df.groupby(\"user_id\")[\"steps\"].transform(\n",
        "        lambda x: x.rolling(7, min_periods=1).mean()\n",
        "    )\n",
        "\n",
        "    FEATURE_DF = df.copy()\n",
        "\n",
        "    # ---------- Prophet ----------\n",
        "    plot = []\n",
        "    try:\n",
        "        p_df = (\n",
        "            df.groupby(\"date\")[\"heart_rate\"]\n",
        "            .mean()\n",
        "            .reset_index()\n",
        "            .rename(columns={\"date\": \"ds\", \"heart_rate\": \"y\"})\n",
        "        )\n",
        "        if len(p_df) > 10:\n",
        "            m = Prophet()\n",
        "            m.fit(p_df)\n",
        "            f = m.predict(p_df)\n",
        "            p_df[\"yhat\"] = f[\"yhat\"]\n",
        "            plot = p_df.tail(30).to_dict(\"records\")\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "    # ---------- DBSCAN ----------\n",
        "    X = FEATURE_DF[[\"heart_rate\", \"steps\", \"sleep\", \"hr_7d_mean\"]].fillna(0)\n",
        "    X = StandardScaler().fit_transform(X)\n",
        "\n",
        "    db = DBSCAN(eps=1.2, min_samples=5)\n",
        "    FEATURE_DF[\"cluster\"] = db.fit_predict(X)\n",
        "    FEATURE_DF[\"cluster_anomaly\"] = FEATURE_DF[\"cluster\"] == -1\n",
        "\n",
        "    FEATURE_DF.to_csv(\"feature_data.csv\", index=False)\n",
        "\n",
        "    return {\"status\": \"success\", \"sample_plot\": plot}\n",
        "\n",
        "# ==================================================\n",
        "# MODULE 3 â€“ ANOMALY DETECTION\n",
        "# ==================================================\n",
        "@app.post(\"/module3\")\n",
        "def module3():\n",
        "    global FEATURE_DF, ALERTS_DF\n",
        "\n",
        "    if FEATURE_DF is None:\n",
        "        return JSONResponse(status_code=400, content={\"error\": \"Run Module 2 first\"})\n",
        "\n",
        "    rows = []\n",
        "\n",
        "    for _, r in FEATURE_DF.iterrows():\n",
        "        if r[\"heart_rate\"] > 120:\n",
        "            rows.append((r[\"user_id\"], r[\"date\"], \"heart_rate_high\"))\n",
        "        if r[\"heart_rate\"] < 40:\n",
        "            rows.append((r[\"user_id\"], r[\"date\"], \"heart_rate_low\"))\n",
        "        if r[\"sleep\"] < 4 or r[\"sleep\"] > 12:\n",
        "            rows.append((r[\"user_id\"], r[\"date\"], \"sleep_abnormal\"))\n",
        "        if r[\"cluster_anomaly\"]:\n",
        "            rows.append((r[\"user_id\"], r[\"date\"], \"cluster_outlier\"))\n",
        "\n",
        "    df = pd.DataFrame(rows, columns=[\"user_id\", \"date\", \"metric\"])\n",
        "\n",
        "    alerts = (\n",
        "        df.groupby([\"user_id\", \"metric\"])\n",
        "        .agg(count=(\"date\", \"count\"))\n",
        "        .reset_index()\n",
        "    )\n",
        "\n",
        "    alerts[\"severity\"] = alerts[\"count\"].apply(\n",
        "        lambda x: \"High\" if x >= 5 else \"Medium\" if x >= 3 else \"Low\"\n",
        "    )\n",
        "\n",
        "    ALERTS_DF = alerts\n",
        "    alerts.to_csv(\"module3_alerts.csv\", index=False)\n",
        "\n",
        "    return {\"status\": \"success\", \"alerts\": alerts.to_dict(\"records\")}\n",
        "\n",
        "# ==================================================\n",
        "# MODULE 4 â€“ INSIGHTS\n",
        "# ==================================================\n",
        "@app.post(\"/module4\")\n",
        "def module4():\n",
        "    if ALERTS_DF is None or ALERTS_DF.empty:\n",
        "        return JSONResponse(status_code=400, content={\"error\": \"Run Module 3 first\"})\n",
        "\n",
        "    insights = [\n",
        "        {\n",
        "            \"user_id\": r[\"user_id\"],\n",
        "            \"severity\": r[\"severity\"],\n",
        "            \"insight\": f\"User {r['user_id']} has {r['severity']} risk due to {r['metric']}\"\n",
        "        }\n",
        "        for _, r in ALERTS_DF.iterrows()\n",
        "    ]\n",
        "\n",
        "    return {\"status\": \"success\", \"insights\": insights}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SOH1KTSHym_3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f290e3e5-f87f-4a23-9953-bc18371d285d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FastAPI URL: NgrokTunnel: \"https://chrematistic-commonsensical-mellie.ngrok-free.dev\" -> \"http://localhost:8000\"\n"
          ]
        }
      ],
      "source": [
        "from pyngrok import ngrok\n",
        "import uvicorn\n",
        "import threading\n",
        "\n",
        "# Kill any existing ngrok processes to avoid 'simultaneous sessions' error\n",
        "!pkill -f ngrok\n",
        "\n",
        "public_url = ngrok.connect(8000)\n",
        "print(\"FastAPI URL:\", public_url)\n",
        "\n",
        "threading.Thread(\n",
        "    target=uvicorn.run,\n",
        "    kwargs={\"app\": \"backend:app\", \"host\": \"0.0.0.0\", \"port\": 8000}\n",
        ").start()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0RIGdjXFks8R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd13d33d-5116-4b21-ed51-19b16cd223b1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing app.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "import requests\n",
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "\n",
        "BACKEND_URL = \"http://localhost:8000\"\n",
        "\n",
        "st.set_page_config(\n",
        "    page_title=\"FitPulse â€“ Health Anomaly Detection\",\n",
        "    layout=\"wide\"\n",
        ")\n",
        "\n",
        "# HEADER\n",
        "st.title(\" FitPulse Health Monitoring Dashboard\")\n",
        "st.caption(\"AI-powered detection of unusual health patterns from fitness device data\")\n",
        "st.divider()\n",
        "\n",
        "# SIDEBAR â€“ FILE UPLOAD\n",
        "st.sidebar.header(\"ðŸ“‚ Upload Fitness Data\")\n",
        "\n",
        "uploaded_file = st.sidebar.file_uploader(\n",
        "    \"Upload CSV file\",\n",
        "    type=[\"csv\"]\n",
        ")\n",
        "\n",
        "if uploaded_file:\n",
        "    with st.spinner(\"Preparing data...\"):\n",
        "        res = requests.post(\n",
        "            f\"{BACKEND_URL}/preprocess\",\n",
        "            files={\"file\": uploaded_file}\n",
        "        )\n",
        "\n",
        "    if res.status_code == 200:\n",
        "        st.sidebar.success(\"Data processed successfully\")\n",
        "        st.sidebar.metric(\"Records Loaded\", res.json()[\"rows\"])\n",
        "    else:\n",
        "        st.sidebar.error(res.json()[\"error\"])\n",
        "\n",
        "# LOAD CLEAN DATA\n",
        "@st.cache_data\n",
        "def load_clean():\n",
        "    return pd.read_csv(\"clean_data.csv\", parse_dates=[\"date\"])\n",
        "\n",
        "try:\n",
        "    df = load_clean()\n",
        "except:\n",
        "    df = None\n",
        "\n",
        "# FILTERS\n",
        "st.subheader(\" Filters\")\n",
        "\n",
        "if df is not None:\n",
        "    c1, c2, c3 = st.columns(3)\n",
        "\n",
        "    with c1:\n",
        "        users = [\"All\"] + sorted(df[\"user_id\"].unique().tolist())\n",
        "        selected_user = st.selectbox(\"User\", users)\n",
        "\n",
        "    with c2:\n",
        "        start_date, end_date = st.date_input(\n",
        "            \"Date Range\",\n",
        "            value=[df[\"date\"].min(), df[\"date\"].max()]\n",
        "        )\n",
        "\n",
        "    with c3:\n",
        "        metric = st.selectbox(\n",
        "            \"Health Metric\",\n",
        "            [\"Heart Rate\", \"Sleep\", \"Steps\"]\n",
        "        )\n",
        "\n",
        "    if selected_user != \"All\":\n",
        "        df = df[df[\"user_id\"] == selected_user]\n",
        "\n",
        "    df = df[\n",
        "        (df[\"date\"] >= pd.to_datetime(start_date)) &\n",
        "        (df[\"date\"] <= pd.to_datetime(end_date))\n",
        "    ]\n",
        "\n",
        "else:\n",
        "    st.info(\"Upload data to activate dashboard\")\n",
        "    st.stop()\n",
        "\n",
        "st.divider()\n",
        "\n",
        "# TABS\n",
        "tab1, tab2, tab3, tab4 = st.tabs([\n",
        "    \" Overview\",\n",
        "    \" Pattern Analysis\",\n",
        "    \" Anomalies\",\n",
        "    \" Insights & Reports\"\n",
        "])\n",
        "\n",
        "# TAB 1 â€“ OVERVIEW\n",
        "with tab1:\n",
        "    st.subheader(\" Data Overview\")\n",
        "\n",
        "    c1, c2, c3 = st.columns(3)\n",
        "    c1.metric(\"Users\", df[\"user_id\"].nunique())\n",
        "    c2.metric(\"Days\", df[\"date\"].nunique())\n",
        "\n",
        "    if metric == \"Heart Rate\":\n",
        "        c3.metric(\"Avg HR\", round(df[\"heart_rate\"].mean(), 1))\n",
        "        y_col = \"heart_rate\"\n",
        "    elif metric == \"Sleep\":\n",
        "        c3.metric(\"Avg Sleep (hrs)\", round(df[\"sleep\"].mean(), 2))\n",
        "        y_col = \"sleep\"\n",
        "    else:\n",
        "        c3.metric(\"Avg Steps\", int(df[\"steps\"].mean()))\n",
        "        y_col = \"steps\"\n",
        "\n",
        "    fig = px.line(\n",
        "        df,\n",
        "        x=\"date\",\n",
        "        y=y_col,\n",
        "        color=\"user_id\",\n",
        "        title=f\"{metric} Trend\"\n",
        "    )\n",
        "    st.plotly_chart(fig, use_container_width=True)\n",
        "\n",
        "    st.dataframe(df.head(50), use_container_width=True)\n",
        "\n",
        "# TAB 2 â€“ PATTERN ANALYSIS\n",
        "with tab2:\n",
        "    st.subheader(\" Health Pattern Analysis\")\n",
        "\n",
        "    if st.button(\"Run Analysis\"):\n",
        "        with st.spinner(\"Running analysis...\"):\n",
        "            res = requests.post(f\"{BACKEND_URL}/module2\")\n",
        "\n",
        "        if res.status_code == 200:\n",
        "            st.success(\"Analysis completed\")\n",
        "\n",
        "            # -------- Heart Rate Trend --------\n",
        "            hr_plot = res.json().get(\"heart_rate_plot\", [])\n",
        "            if hr_plot:\n",
        "                pdf = pd.DataFrame(hr_plot)\n",
        "                fig = px.line(\n",
        "                    pdf,\n",
        "                    x=\"ds\",\n",
        "                    y=[\"y\", \"yhat\"],\n",
        "                    title=\"Heart Rate vs Baseline\"\n",
        "                )\n",
        "                st.plotly_chart(fig, use_container_width=True)\n",
        "\n",
        "            # -------- Sleep Trend --------\n",
        "            sleep_plot = res.json().get(\"sleep_plot\", [])\n",
        "            if sleep_plot:\n",
        "                sdf = pd.DataFrame(sleep_plot)\n",
        "                fig = px.line(\n",
        "                    sdf,\n",
        "                    x=\"date\",\n",
        "                    y=\"sleep\",\n",
        "                    title=\"Sleep Duration Trend\"\n",
        "                )\n",
        "                st.plotly_chart(fig, use_container_width=True)\n",
        "\n",
        "            # -------- Cluster Scatter --------\n",
        "            cluster_plot = res.json().get(\"cluster_plot\", [])\n",
        "            if cluster_plot:\n",
        "                cdf = pd.DataFrame(cluster_plot)\n",
        "                cdf[\"type\"] = cdf[\"cluster_anomaly\"].map(\n",
        "                    {True: \"Outlier\", False: \"Normal\"}\n",
        "                )\n",
        "\n",
        "                fig = px.scatter(\n",
        "                    cdf,\n",
        "                    x=\"pca_x\",\n",
        "                    y=\"pca_y\",\n",
        "                    color=\"type\",\n",
        "                    title=\"Behavior Clustering (DBSCAN + PCA)\",\n",
        "                    opacity=0.7\n",
        "                )\n",
        "                st.plotly_chart(fig, use_container_width=True)\n",
        "\n",
        "        else:\n",
        "            st.error(res.json()[\"error\"])\n",
        "\n",
        "# TAB 3 â€“ ANOMALIES\n",
        "with tab3:\n",
        "    st.subheader(\" Detected Health Anomalies\")\n",
        "\n",
        "    if st.button(\"Detect Anomalies\"):\n",
        "        with st.spinner(\"Detecting anomalies...\"):\n",
        "            res = requests.post(f\"{BACKEND_URL}/module3\")\n",
        "\n",
        "        if res.status_code == 200:\n",
        "            alerts = pd.DataFrame(res.json()[\"alerts\"])\n",
        "\n",
        "            if selected_user != \"All\":\n",
        "                alerts = alerts[alerts[\"user_id\"] == selected_user]\n",
        "\n",
        "            if not alerts.empty:\n",
        "                st.dataframe(alerts, use_container_width=True)\n",
        "\n",
        "                fig = px.bar(\n",
        "                    alerts,\n",
        "                    x=\"metric\",\n",
        "                    y=\"count\",\n",
        "                    color=\"severity\",\n",
        "                    title=\"Anomaly Summary\"\n",
        "                )\n",
        "                st.plotly_chart(fig, use_container_width=True)\n",
        "            else:\n",
        "                st.info(\"No anomalies detected\")\n",
        "        else:\n",
        "            st.error(res.json()[\"error\"])\n",
        "\n",
        "# TAB 4 â€“ INSIGHTS & REPORTS\n",
        "with tab4:\n",
        "    st.subheader(\" Health Insights\")\n",
        "\n",
        "    if st.button(\"Generate Insights\"):\n",
        "        with st.spinner(\"Generating insights...\"):\n",
        "            res = requests.post(f\"{BACKEND_URL}/module4\")\n",
        "\n",
        "        if res.status_code == 200:\n",
        "            for i in res.json()[\"insights\"]:\n",
        "                st.warning(\n",
        "                    f\" User {i['user_id']} â€” {i['severity']} Risk\\n\\n\"\n",
        "                    f\"{i['insight']}\"\n",
        "                )\n",
        "        else:\n",
        "            st.error(res.json()[\"error\"])\n",
        "\n",
        "    st.divider()\n",
        "    st.subheader(\"Downloads\")\n",
        "\n",
        "    try:\n",
        "        st.download_button(\n",
        "            \"Download Clean Data\",\n",
        "            open(\"clean_data.csv\", \"rb\"),\n",
        "            file_name=\"clean_data.csv\"\n",
        "        )\n",
        "\n",
        "        st.download_button(\n",
        "            \"Download Alerts Report\",\n",
        "            open(\"module3_alerts.csv\", \"rb\"),\n",
        "            file_name=\"health_alerts.csv\"\n",
        "        )\n",
        "    except:\n",
        "        st.info(\"Reports available after analysis\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "djs9hykny-Cx"
      },
      "outputs": [],
      "source": [
        "!streamlit run app.py &>/content/logs.txt &"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MqSZsuwSrS1h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a385f6e0-885c-4f8b-861a-9e66a83db67f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Streamlit public URL: NgrokTunnel: \"https://chrematistic-commonsensical-mellie.ngrok-free.dev\" -> \"http://localhost:8501\"\n"
          ]
        }
      ],
      "source": [
        "from pyngrok import ngrok\n",
        "streamlit_url = ngrok.connect(8501)\n",
        "print(\"Streamlit public URL:\", streamlit_url)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h-GY9xNT6ZYg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c55740e1-fb9f-461d-be2e-158319126b38"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
            "\u001b[0m\n",
            "2026-01-13 15:41:05.738 Port 8501 is already in use\n"
          ]
        }
      ],
      "source": [
        "!streamlit run app.py --server.port 8501 --server.address 0.0.0.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fXWQgIXZrzU1"
      },
      "outputs": [],
      "source": [
        "#!pkill -f ngrok\n",
        "#!pkill -f uvicorn"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}